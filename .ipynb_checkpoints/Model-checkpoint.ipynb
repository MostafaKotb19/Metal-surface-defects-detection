{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a64b5199",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pydot, graphviz\n",
    "from tensorflow.keras.utils import plot_model\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import regularizers\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, Flatten, Dropout, concatenate, GlobalAveragePooling2D, Reshape\n",
    "from tensorflow.keras.layers import Permute\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Model\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import gridspec\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import pandas as pd\n",
    "import xml.etree.ElementTree as ET\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from PIL import Image\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from keras import Model\n",
    "import torch\n",
    "from transformers import ViTFeatureExtractor, ViTModel\n",
    "from torchvision.models import vision_transformer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b771ee4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = {\n",
    "    \"1_chongkong\" : 0,\n",
    "    \"2_hanfeng\" : 1,\n",
    "    \"3_yueyawan\": 2,\n",
    "    \"4_shuiban\": 3,\n",
    "    \"5_youban\": 4,\n",
    "    \"6_siban\": 5,\n",
    "    \"7_yiwu\": 6,\n",
    "    \"8_yahen\": 11,\n",
    "    \"9_zhehen\": 7,\n",
    "    \"10_yaozhed\": 8,\n",
    "    \"scratches\": 9,\n",
    "    \"rolled-in_scale\": 10\n",
    "}\n",
    "mapping2 = {\n",
    "    0 : \"Punching Hole\",\n",
    "    1 : \"Welding Line\",\n",
    "    2 : \"Crescent Gap\",\n",
    "    3 : \"Water Spot\",\n",
    "    4 : \"Oil Spot\",\n",
    "    5 : \"Silk Spot\",\n",
    "    6 : \"Inclusion\",\n",
    "    11 : \"Rolled Pit\",\n",
    "    7 : \"Crease\",\n",
    "    8 : \"Waist Folding\",\n",
    "    9 : \"Scratches\",\n",
    "    10 : \"Rolled in Scale\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d3e40ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []\n",
    "X_train = []\n",
    "y_train = []\n",
    "X_val = []\n",
    "y_val = []\n",
    "X_test = []\n",
    "y_test = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd280efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "w_factor = 2048/224.0\n",
    "l_factor = 1000/224.0\n",
    "w = 224\n",
    "l = 224\n",
    "w_factor_2 = 200/224.0\n",
    "l_factor_2 = 200/224.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "508d23d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_annotations(directory, class_name, idx):\n",
    "\n",
    "    try:\n",
    "        tree = ET.parse(directory)\n",
    "        root = tree.getroot()\n",
    "        boxes = []\n",
    "        defect = -1\n",
    "        objs = root.findall('object')\n",
    "        for i in objs:\n",
    "            name = i.find('name').text\n",
    "            defect = mapping.get(name, 12)\n",
    "            if defect != 12 and defect != 11:\n",
    "                box = i.find('bndbox')\n",
    "                xmin = float(box.find('xmin').text)\n",
    "                ymin = float(box.find('ymin').text)\n",
    "                xmax = float(box.find('xmax').text)\n",
    "                ymax = float(box.find('ymax').text)\n",
    "\n",
    "                if defect == -1:\n",
    "                    return 0\n",
    "                if xmin > xmax:\n",
    "                    temp = xmin\n",
    "                    xmin = xmax\n",
    "                    xmax = temp\n",
    "                if ymin > ymax:\n",
    "                    temp = ymin\n",
    "                    ymin = ymax\n",
    "                    ymax = temp\n",
    "\n",
    "                box = []\n",
    "                for i in range(5):\n",
    "                    box.append(-1)\n",
    "                box[0] = defect\n",
    "                if class_name !='inclusion':\n",
    "                    box[1] = (xmin)/w_factor\n",
    "                    box[2] = (ymin)/l_factor\n",
    "                    box[3] = (xmax)/w_factor\n",
    "                    box[4] = (ymax)/l_factor\n",
    "                elif (class_name=='inclusion' and idx<217):\n",
    "                    box[1] = (xmin)/w_factor\n",
    "                    box[2] = (ymin)/l_factor\n",
    "                    box[3] = (xmax)/w_factor\n",
    "                    box[4] = (ymax)/l_factor\n",
    "                \n",
    "                elif (class_name=='inclusion' and idx>= 217):\n",
    "                    box[1] = (xmin)/w_factor_2\n",
    "                    box[2] = (ymin)/l_factor_2\n",
    "                    box[3] = (xmax)/w_factor_2\n",
    "                    box[4] = (ymax)/l_factor_2\n",
    "                    \n",
    "                boxes.append(box)\n",
    "            else:\n",
    "                defect = -1\n",
    "        if defect == -1:\n",
    "            return 0\n",
    "        return boxes\n",
    "    except:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa234139",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(get_annotations(\"D:\\Datasets_PBL\\lable\\crease (1).xml\",'crease', 1 ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f18c548c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir= 'D:\\\\Datasets_PBL\\\\gc10det'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96fd6c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_items = os.listdir(data_dir)\n",
    "categories = [item for item in all_items if os.path.isdir(os.path.join(data_dir, item))]\n",
    "print(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad706e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_images=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ffca1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for category in categories:\n",
    "    category_path= os.path.join(data_dir, category)\n",
    "    for img in os.listdir(category_path):\n",
    "        img_path= os.path.join(category_path, img)\n",
    "        img = cv2.imread(img_path)\n",
    "        img = cv2.resize(img, (100, 100))\n",
    "        sample_images.append(img)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "525eb9bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15, 15))\n",
    "spec = gridspec.GridSpec(ncols=3, nrows=4,\n",
    "                         width_ratios=[1, 1, 1], wspace=0.4,\n",
    "                         hspace=0.4, height_ratios=[1, 1, 1, 1])\n",
    "fig.suptitle(\"Sample images for 11 classes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105aa912",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(sample_images)):\n",
    "    ax = fig.add_subplot(3, 4, i+1)\n",
    "    ax.imshow(sample_images[i], cmap='gray')\n",
    "    ax.set_title(f\"{categories[i]}\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e8e5a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b10e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "for category in categories:\n",
    "    category_path= os.path.join(data_dir, category)\n",
    "    cnt=1\n",
    "    for img in os.listdir(category_path):\n",
    "        img_path= os.path.join(category_path, img)\n",
    "        img= cv2.imread(img_path)\n",
    "        annotation = get_annotations(f\"D:\\Datasets_PBL\\lable\\{category} ({cnt}).xml\", category, cnt)\n",
    "        if (annotation):\n",
    "            img = cv2.resize(img, (w, l))\n",
    "#             img= cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "#             img= np.expand_dims(img, axis=0)\n",
    "            X.append(img)\n",
    "            y.append(annotation)\n",
    "            cnt+=1  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75045a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.125, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b408b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8886b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_gt(y):\n",
    "    classes = []\n",
    "    dims = []\n",
    "    for i in range(len(y)):\n",
    "        tmp_classes = []\n",
    "        tmp_dims = []\n",
    "        for j in range(len(y[i])):\n",
    "            tmp_classes.append(y[i][j][0])\n",
    "            tmp_dims.append(y[i][j][1:])\n",
    "        classes.append(tmp_classes)\n",
    "        dims.append(tmp_dims)\n",
    "    return classes, dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "894da728",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes_train, dims_train = split_gt(y_train)\n",
    "classes_val, dims_val = split_gt(y_val)\n",
    "classes_test, dims_test = split_gt(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a0f4a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(X_train, dtype = 'float')\n",
    "X_test = np.array(X_test, dtype = 'float')\n",
    "X_val = np.array(X_val, dtype = 'float')\n",
    "\n",
    "\n",
    "#X_train /= 255.0\n",
    "#X_test /= 255\n",
    "#X_val/= 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26078b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_min(lst, index):\n",
    "    minn = 10000000\n",
    "    for i in range(len(lst)):\n",
    "        for j in range(len(lst[i])):\n",
    "            if lst[i][j][index] < minn:\n",
    "                minn = lst[i][j][index]\n",
    "    return minn\n",
    "\n",
    "def extract_max(lst, index):\n",
    "    maxx = -10000000\n",
    "    for i in range(len(lst)):\n",
    "        for j in range(len(lst[i])):\n",
    "            if lst[i][j][index] > maxx:\n",
    "                maxx = lst[i][j][index]\n",
    "    return maxx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41838418",
   "metadata": {},
   "outputs": [],
   "source": [
    "def maxminscaler(lst, maxx, minn, index):\n",
    "    for i in range(len(lst)):\n",
    "        for j in range(len(lst[i])):\n",
    "            lst[i][j][index] = (lst[i][j][index] - minn)/(maxx - minn)\n",
    "    return lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13fcc5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "xmin_min = extract_min(dims_train, 0)\n",
    "xmin_max = extract_max(dims_train, 0)\n",
    "xmax_min = extract_min(dims_train, 1)\n",
    "xmax_max = extract_max(dims_train, 1)\n",
    "ymin_min = extract_min(dims_train, 2)\n",
    "ymin_max = extract_max(dims_train, 2)\n",
    "ymax_min = extract_min(dims_train, 3)\n",
    "ymax_max = extract_max(dims_train, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde494f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dims_train = maxminscaler(dims_train, xmin_min, xmin_max, 0)\n",
    "dims_train = maxminscaler(dims_train, xmax_min, xmax_max, 1)\n",
    "dims_train = maxminscaler(dims_train, ymin_min, ymin_max, 2)\n",
    "dims_train = maxminscaler(dims_train, ymax_min, ymax_max, 3)\n",
    "\n",
    "dims_val = maxminscaler(dims_val, xmin_min, xmin_max, 0)\n",
    "dims_val = maxminscaler(dims_val, xmax_min, xmax_max, 1)\n",
    "dims_val = maxminscaler(dims_val, ymin_min, ymin_max, 2)\n",
    "dims_val = maxminscaler(dims_val, ymax_min, ymax_max, 3)\n",
    "\n",
    "dims_test = maxminscaler(dims_test, xmin_min, xmin_max, 0)\n",
    "dims_test = maxminscaler(dims_test, xmax_min, xmax_max, 1)\n",
    "dims_test = maxminscaler(dims_test, ymin_min, ymin_max, 2)\n",
    "dims_test = maxminscaler(dims_test, ymax_min, ymax_max, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b0f0d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "maximum_defects = 0\n",
    "for i in dims_val:\n",
    "    if len(i) > maximum_defects:\n",
    "        maximum_defects = len(i)\n",
    "\n",
    "print(maximum_defects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb2cf6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_dims(lst):\n",
    "    pad = [0, 0, 0, 0]\n",
    "    for i in range(len(lst)):\n",
    "        for _ in range(11 - len(lst[i])):\n",
    "            lst[i].append(pad)\n",
    "    return lst\n",
    "\n",
    "def pad_classes(lst):\n",
    "    pad = -1\n",
    "    for i in range(len(lst)):\n",
    "        for _ in range(11 - len(lst[i])):\n",
    "            lst[i].append(pad)\n",
    "    return lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c3c129",
   "metadata": {},
   "outputs": [],
   "source": [
    "dims_train = pad_dims(dims_train)\n",
    "dims_val = pad_dims(dims_val)\n",
    "dims_test = pad_dims(dims_test)\n",
    "classes_train = pad_classes(classes_train)\n",
    "classes_val = pad_classes(classes_val)\n",
    "classes_test = pad_classes(classes_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957976e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 12\n",
    "\n",
    "for i in range(len(classes_train)):\n",
    "    classes_train[i] = np.array(classes_train[i], dtype = 'float').astype('float64').reshape((-1,1))\n",
    "    classes_train[i] = np_utils.to_categorical(classes_train[i], num_classes=num_classes)\n",
    "\n",
    "for i in range(len(dims_train)):\n",
    "    dims_train[i] = np.array(dims_train[i], dtype = 'float')\n",
    "\n",
    "for i in range(len(classes_val)):\n",
    "    classes_val[i] = np.array(classes_val[i], dtype = 'float').astype('float64').reshape((-1,1))\n",
    "    classes_val[i] = np_utils.to_categorical(classes_val[i], num_classes=num_classes)\n",
    "\n",
    "for i in range(len(dims_val)):\n",
    "    dims_val[i] = np.array(dims_val[i], dtype = 'float')\n",
    "\n",
    "for i in range(len(classes_test)):\n",
    "    classes_test[i] = np.array(classes_test[i], dtype = 'float').astype('float64').reshape((-1,1))\n",
    "    classes_test[i] = np_utils.to_categorical(classes_test[i], num_classes=num_classes)\n",
    "\n",
    "for i in range(len(dims_test)):\n",
    "    dims_test[i] = np.array(dims_test[i], dtype = 'float')\n",
    "\n",
    "num_regressors = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f7a8a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(dims_val)):\n",
    "    if (len(dims_val[i])!=11):\n",
    "        print(i)\n",
    "    #print(len(i))\n",
    "#dims_val[288]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1584717",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(dims_train[0]))\n",
    "dims_train = np.array(dims_train, dtype = 'float')\n",
    "dims_val = np.array(dims_val, dtype = 'float')\n",
    "dims_test = np.array(dims_test, dtype = 'float')\n",
    "classes_train = np.array(classes_train, dtype = 'float')\n",
    "classes_val = np.array(classes_val, dtype = 'float')\n",
    "classes_test = np.array(classes_test, dtype = 'float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c45676d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoImageProcessor, TFViTModel\n",
    "image_processor = AutoImageProcessor.from_pretrained(\"google/vit-base-patch16-224-in21k\")\n",
    "extract = TFViTModel.from_pretrained(\"google/vit-base-patch16-224-in21k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b10aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_CE(y_true, y_pred):\n",
    "    # Reshape to one-dimensional tensors\n",
    "    y_true = tf.reshape(y_true, shape=(-1,))\n",
    "    y_pred = tf.reshape(y_pred, shape=(-1,))\n",
    "\n",
    "    log_y_pred = tf.math.log(y_pred)\n",
    "    element_wise = -tf.math.multiply_no_nan(x=log_y_pred, y=y_true)\n",
    "    x = tf.reduce_mean(element_wise)\n",
    "    return x\n",
    "\n",
    "def categorical_crossentropy2(y_true, y_pred):\n",
    "    m = len(y_true)\n",
    "    loss = tf.zeros([])\n",
    "    for i in range(len(y_true)):\n",
    "        for j in range(len(y_true[i])):\n",
    "            loss += my_CE(y_true[i][j], y_pred[i][j])\n",
    "\n",
    "    loss /= tf.cast(m, tf.float32)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0fadf4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.8  # Allocate 80% of the available GPU memory\n",
    "tf.compat.v1.keras.backend.set_session(tf.compat.v1.Session(config=config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "875e2972",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy2(y_true, y_pred):\n",
    "    m= len(y_true)\n",
    "    accuracy=0\n",
    "    for i in range(len(y_true)):\n",
    "        for j in range(len(y_true[i])):\n",
    "            mask = tf.not_equal(tf.argmax(y_true[i][j], axis=-1), 11)  # Exclude class 12 (index 11)\n",
    "            if (not mask): continue\n",
    "            correct_predictions = tf.equal(tf.argmax(y_true[i][j], axis=-1), tf.argmax(y_pred[i][j], axis=-1))\n",
    "            accuracy += tf.reduce_mean(tf.cast(correct_predictions, tf.float32))\n",
    "\n",
    "    accuracy/=m\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "956b0f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae63d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if logs.get('class_output_accuracy2') is not None and logs.get('class_output_accuracy2') > 0.85 \\\n",
    "        and logs.get('val_class_output_accuracy2') is not None and logs.get('val_class_output_accuracy2') > 0.8:\n",
    "            self.model.stop_training = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d60404",
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks= myCallback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95741167",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20882b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a58269e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_1= image_processor(X_train, return_tensors=\"tf\")\n",
    "X_val_1= image_processor(X_val, return_tensors=\"tf\")\n",
    "X_test_1= image_processor(X_test, return_tensors=\"tf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e55fc5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_2= X_train_1['pixel_values']\n",
    "X_val_2 = X_val_1['pixel_values']\n",
    "X_test_2 = X_test_1['pixel_values']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "634f3f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_ext = extract(X_train_2)\n",
    "X_val_ext = extract(X_val_2)\n",
    "x_test_ext = extract(X_test_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc4c1833",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow.keras import initializers\n",
    "input_shape = (1, 224, 224)\n",
    "\n",
    "inputs = Input(shape=input_shape)\n",
    "\n",
    "flatten = Flatten()(inputs)\n",
    "\n",
    "dense_class1 = Dense(512, activation='relu', kernel_initializer=initializers.GlorotUniform(),\n",
    "                    kernel_regularizer=tf.keras.regularizers.l2(0.001))(flatten)\n",
    "drop1=Dropout(0.2)(dense_class1)\n",
    "\n",
    "dense_class2 = Dense(256, activation='relu', kernel_initializer=initializers.GlorotUniform(),\n",
    "                    kernel_regularizer=tf.keras.regularizers.l2(0.001))(drop1)\n",
    "drop2=Dropout(0.2)(dense_class2)\n",
    "output_class = Dense(11*12, activation='relu', kernel_initializer=initializers.GlorotUniform(),\n",
    "                     kernel_regularizer=tf.keras.regularizers.l2(0.001))(drop2)\n",
    "output_class = Reshape((11, 12))(output_class)\n",
    "\n",
    "softmax_layers = []\n",
    "for i in range(11):\n",
    "    row = tf.keras.layers.Lambda(lambda x: x[:, :, i])(output_class)\n",
    "    softmax= Dense(12, activation='softmax')(row)\n",
    "#     softmax = tf.keras.layers.Softmax()(row)\n",
    "    softmax_layers.append(softmax)\n",
    "\n",
    "output_class2 = tf.keras.layers.Concatenate(axis=-1)(softmax_layers)\n",
    "output_class2 = Reshape((11, 12), name='class_output')(output_class2)\n",
    "\n",
    "\n",
    "\n",
    "dense_reg1 = Dense(128, activation='relu')(flatten)\n",
    "dropout1= Dropout(0.2)(dense_reg1)\n",
    "dense_reg2 = Dense(128, activation='relu')(dropout1)\n",
    "dropout2=  Dropout(0.2)(dense_reg2)\n",
    "dense_reg3 = Dense(64, activation='relu')(dropout2)\n",
    "dense_reg4 = Dense(64, activation='relu')(dense_reg3)\n",
    "output_reg = Dense(11*4)(dense_reg4)\n",
    "output_reg = Reshape((11, 4))(output_reg)\n",
    "\n",
    "\n",
    "reg_layers = []\n",
    "for i in range(11):\n",
    "    row = tf.keras.layers.Lambda(lambda x: x[:, i])(output_reg)\n",
    "    out= Dense(4)(row)\n",
    "    reg_layers.append(out)\n",
    "\n",
    "reg_output2 = tf.keras.layers.Concatenate(axis=-1)(reg_layers)\n",
    "reg_output2 = Reshape((11, 4), name='reg_output')(reg_output2)\n",
    "\n",
    "\n",
    "model = Model(inputs=inputs, outputs=[output_class2, reg_output2])\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=0.01, momentum= 0.9, clipnorm=1)\n",
    "model.compile(optimizer='SGD',\n",
    "              loss={'class_output': categorical_crossentropy2,\n",
    "                    'reg_output': 'mse'},\n",
    "              loss_weights={'class_output': 1.0, 'reg_output': 1.0},\n",
    "              metrics={'class_output': accuracy2,\n",
    "                       'reg_output': 'mae'}, run_eagerly=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2388e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5704698",
   "metadata": {},
   "outputs": [],
   "source": [
    "#with tf.device('/CPU:0'):\n",
    "H = model.fit(X_train_ext, {'class_output': classes_train, 'reg_output': dims_train},\n",
    "                    validation_data=(X_val_ext, {'class_output': classes_val, 'reg_output': dims_val}),\n",
    "                    batch_size=8, epochs=200, callbacks= [callbacks])\n",
    "model.save(\"annotations_multi_transformers.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0649ec88",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 100\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "#plt.plot(np.arange(0, N), H.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(np.arange(0, N), H.history[\"class_output_loss\"], label=\"train_class_loss\")\n",
    "plt.plot(np.arange(0, N), H.history[\"reg_output_loss\"], label=\"train_reg_loss\")\n",
    "plt.plot(np.arange(0, N), H.history[\"class_output_accuracy2\"], label=\"train_accuracy\")\n",
    "plt.plot(np.arange(0, N), H.history[\"reg_output_mae\"], label=\"train_mae\")\n",
    "#plt.plot(np.arange(0, N), H.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot(np.arange(0, N), H.history[\"val_class_output_loss\"], label=\"val_class_loss\")\n",
    "plt.plot(np.arange(0, N), H.history[\"val_reg_output_loss\"], label=\"val_reg_loss\")\n",
    "plt.plot(np.arange(0, N), H.history[\"val_class_output_accuracy2\"], label=\"val_accuracy\")\n",
    "plt.plot(np.arange(0, N), H.history[\"val_reg_output_mae\"], label=\"val_mae\")\n",
    "plt.title(\"Training Loss and MAE\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ead5925",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inv_minmax_scaler(val, minn, maxx):\n",
    "    return ((val *(maxx-minn))+ minn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b53eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(img_path, xml_path):\n",
    "    img = cv2.imread(img_path)\n",
    "    img2 = cv2.resize(img, (w, l))\n",
    "    img= cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)\n",
    "    img= np.expand_dims(img, axis=0)\n",
    "    img= np.reshape(img, (1, 1, 224, 224))\n",
    "    img = feature_extractor(img, return_tensors='tf')\n",
    "    img = img['pixel_values'].numpy()\n",
    "\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 10))\n",
    "    ax.imshow(img2, cmap = 'gray')\n",
    "\n",
    "    pred= model.predict(img)\n",
    "    real= get_annotations(xml_path)\n",
    "\n",
    "    i=0\n",
    "    while(np.argmax(pred[0][0][i])!= 11):\n",
    "\n",
    "        name = np.argmax(pred[0][0][i])\n",
    "        xmin = inv_minmax_scaler(pred[1][0][i][0], xmin_min, xmin_max)\n",
    "        ymin = inv_minmax_scaler(pred[1][0][i][1], ymin_min, ymin_max)\n",
    "        xmax = inv_minmax_scaler(pred[1][0][i][2], xmax_min, xmax_max)\n",
    "        ymax = inv_minmax_scaler(pred[1][0][i][3], ymax_min, ymax_max)\n",
    "\n",
    "        if xmin > xmax:\n",
    "            temp = xmin\n",
    "            xmin = xmax\n",
    "            xmax = temp\n",
    "        if ymin > ymax:\n",
    "            temp = ymin\n",
    "            ymin = ymax\n",
    "            ymax = temp\n",
    "#         print(xmin, ymin, xmax, ymax)\n",
    "\n",
    "        width_rec = xmax - xmin\n",
    "        height_rec = ymax - ymin\n",
    "\n",
    "        rect = plt.Rectangle((xmin, ymin), width_rec, height_rec, fill=False, edgecolor='red')\n",
    "        ax.add_patch(rect)\n",
    "        plt.text(xmin+width_rec/2, ymin+height_rec/2, f'pred {mapping2[name]}', color='red', ha='center', va='center')\n",
    "\n",
    "        if i<= len(real)-1:\n",
    "            name = real[i][0]\n",
    "            xmin = real[i][1]\n",
    "            ymin = real[i][2]\n",
    "            xmax = real[i][3]\n",
    "            ymax = real[i][4]\n",
    "\n",
    "            if xmin > xmax:\n",
    "                temp = xmin\n",
    "                xmin = xmax\n",
    "                xmax = temp\n",
    "            if ymin > ymax:\n",
    "                temp = ymin\n",
    "                ymin = ymax\n",
    "                ymax = temp\n",
    "\n",
    "#             print(xmin, ymin, xmax, ymax)\n",
    "            width_rec = xmax - xmin\n",
    "            height_rec = ymax - ymin\n",
    "\n",
    "            rect2 = plt.Rectangle((xmin, ymin), width_rec, height_rec, fill=False, edgecolor='blue')\n",
    "            ax.add_patch(rect2)\n",
    "            plt.text(xmin+width_rec/2, ymin+height_rec/2, f'real {mapping2[name]}', color='blue', ha='center', va='center')\n",
    "\n",
    "        i+=1\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e7aa08",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=90\n",
    "xml_path= fr'lable/punching_hole ({x}).xml'\n",
    "path= fr'gc10det/punching_hole/punching_hole ({x}).jpg'\n",
    "plot(path, xml_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
